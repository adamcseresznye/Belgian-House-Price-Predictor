








import json
import re
import time
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import plotly.express as px
import requests
import seaborn as sns
import tqdm
from bs4 import BeautifulSoup
from geopy.geocoders import Nominatim
from lets_plot import *
from lets_plot.mapping import as_discrete
from requests_html import HTMLSession
from scipy import stats
# selenium 4
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager

LetsPlot.setup_html()








def extract(type_, page):
    """
    Extracts and returns the BeautifulSoup object from a specified Immoweb search page.

    Args:
        type_ (str): The type of property to search for (e.g., "rent", "sale").
        page (int): The page number of the search results.

    Returns:
        BeautifulSoup: A BeautifulSoup object containing the parsed HTML content of the Immoweb search page.
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.5112.79 Safari/537.36"
    }
    url = f"https://www.immoweb.be/en/search/house/for-{type_}?countries=BE&page={page}&orderBy=relevance"
    r = requests.get(url, headers=headers)
    soup = BeautifulSoup(r.content, "html.parser")
    return soup


def transform(soup):
    """
    Extracts property information from a BeautifulSoup object and appends it to the hitlist.

    Args:
        soup (BeautifulSoup): The BeautifulSoup object containing the parsed HTML content.

    Returns:
        None
    """
    hitlist = []  # Initialize the hitlist within the function

    divs = soup.find_all("article", class_="card card--result card--xl")
    for item in divs:
        # get the type of the property
        title_value = item.find("h2").text.strip()

        # get the price
        price_tag = item.find("p", class_="card--result__price")
        price_attr_value = price_tag.find("iw-price")[":price"]
        price_json = json.loads(price_attr_value)
        price_value = price_json["mainValue"]

        try:
            # get the number of bedrooms
            bedroom_tag = item.find(
                "p",
                class_="card__information card--result__information card__information--property",
            )
            br_attr = bedroom_tag.find("iw-abbreviation")[":abbreviation"]
            br_value = int(re.search(r"\d+", br_attr).group())
        except:
            br_value = np.nan

        try:
            # get the square meter
            sqm_tag = item.find(
                "p",
                class_="card__information card--result__information card__information--property",
            ).text
            sqm_value = int(re.search(r"\d+", sqm_tag).group())
        except:
            sqm_value = np.nan

        # get the ZIP code and location
        ZIP_tag = item.find(
            "p",
            class_="card__information card--results__information--locality card__information--locality",
        ).text
        ZIP_value = int(re.search(r"\d+", ZIP_tag).group())

        location_value = re.sub(r"\b\d+\b", "", ZIP_tag).strip()
        website = item.find("a", href=True)["href"]

        data = {
            # 'time' : pd.Timestamp.now(),
            "title": title_value,
            "price": price_value,
            "ZIP": ZIP_value,
            "city": location_value,
            "bedroom": br_value,
            "surface": sqm_value,
            "website": website,
        }

        hitlist.append(data)





# https://github.com/psf/requests-html/issues/275#issuecomment-513992564
session = HTMLSession(
    browser_args=[
        "--no-sandbox",
        "--user-agent=Mozilla/5.0 (Windows NT 5.1; rv:7.0.1) Gecko/20100101 Firefox/7.0.1",
    ]
)
URL = "https://www.immoweb.be/en/search/house/for-rent?countries=BE&page=1&orderBy=relevance"
r = session.get(URL)
r.html.arender(sleep=1)

print(r.status_code)


ads = r.html.xpath(
    '//*[@id="searchResults"]/div[4]/div/div[1]/div[1]/div[1]', first=True
)

print(ads)

all_tables_from_given_page = []
for item in ads.absolute_links:
    try:
        r = session.get(item)
        r.html.arender(sleep=1)
        tables_from_add = pd.concat(pd.read_html(r.text))
        all_tables_from_given_page.append(tables_from_add)

    except AttributeError:
        pass


URL = "https://www.immoweb.be/en/classified/house/for-rent/woluwe-saint-lambert/1200/10757268"
session = HTMLSession(
    browser_args=[
        "--no-sandbox",
        "--user-agent=Mozilla/5.0 (Windows NT 5.1; rv:7.0.1) Gecko/20100101 Firefox/7.0.1",
    ]
)
r = session.get(URL)
r.html.render(sleep=1)
print(pd.read_html(r.text)[6])


ads


ads = {
    "https://www.immoweb.be/en/classified/house/for-rent/tervuren/3080/10795962",
    "https://www.immoweb.be/en/classified/house/for-rent/waterloo/1410/10403855",
    "https://www.immoweb.be/en/classified/house/for-rent/tervuren/3080/10820557",
    "https://www.immoweb.be/en/classified/house/for-rent/rixensart/1330/10818504",
    "https://www.immoweb.be/en/classified/house/for-rent/zaventem%20sterrebeek/1933/10792058",
    "https://www.immoweb.be/en/classified/house/for-rent/woluwe-saint-pierre/1150/10785377",
    "https://www.immoweb.be/en/classified/exceptional-property/for-rent/ixelles/1050/10815451",
    "https://www.immoweb.be/en/classified/mansion/for-rent/tervuren/3080/10799605",
    "https://www.immoweb.be/en/search/house/for-rent?countries=BE&page=110&orderBy=relevance",
    "https://www.immoweb.be/en/classified/10786920",
    "https://www.immoweb.be/en/classified/house/for-rent/kraainem/1950/10818148",
    "https://www.immoweb.be/en/classified/house/for-rent/waterloo/1410/10633743",
    "https://www.immoweb.be/en/classified/house/for-rent/woluwe-saint-lambert/1200/10810362",
    "https://www.immoweb.be/en/classified/exceptional-property/for-rent/woluwe-saint-pierre/1150/10822313",
    "https://www.immoweb.be/en/classified/house/for-rent/ixelles/1050/10821217",
    "https://www.immoweb.be/en/classified/house/for-rent/waterloo/1410/10597388",
    "https://www.immoweb.be/en/classified/house/for-rent/woluwe-saint-lambert/1200/10816194",
    "https://www.immoweb.be/en/classified/exceptional-property/for-rent/keerbergen/3140/10788298",
    "https://www.immoweb.be/en/search/house/for-rent?countries=BE&page=2&orderBy=relevance",
    "https://www.immoweb.be/en/classified/house/for-rent/kraainem/1950/10802699",
    "https://www.immoweb.be/en/classified/house/for-rent/woluwe-saint-pierre/1150/10802614",
    "https://www.immoweb.be/en/classified/house/for-rent/oppuurs/2880/10816362",
    "https://www.immoweb.be/en/classified/house/for-rent/woluwe-saint-lambert/1200/10763997",
    "https://www.immoweb.be/en/classified/house/for-rent/woluwe-saint-lambert/1200/10738911",
    "https://www.immoweb.be/en/search/house/for-rent?countries=BE&orderBy=relevance",
    "https://www.immoweb.be/en/classified/house/for-rent/rixensart/1330/10722833",
    "https://www.immoweb.be/en/classified/villa/for-rent/waterloo/1410/10809750",
    "https://www.immoweb.be/en/classified/town-house/for-rent/kraainem/1950/10737139",
    "https://www.immoweb.be/en/classified/house/for-rent/rhode-saint-genese/1640/10813232",
    "https://www.immoweb.be/en/classified/house/for-rent/woluwe-saint-lambert/1200/10757268",
    "https://www.immoweb.be/en/classified/house/for-rent/overijse/3090/10803446",
    "https://www.immoweb.be/en/classified/exceptional-property/for-rent/waterloo/1410/10612427",
    "https://www.immoweb.be/en/classified/villa/for-rent/tervuren/3080/10818145",
    "https://www.immoweb.be/en/classified/house/for-rent/woluwe-saint-pierre/1150/10800984",
}


# https://github.com/psf/requests-html/issues/275#issuecomment-513992564

session = HTMLSession(
    browser_args=[
        "--no-sandbox",
        "--user-agent=Mozilla/5.0 (Windows NT 5.1; rv:7.0.1) Gecko/20100101 Firefox/7.0.1",
    ]
)
URL = "https://www.immoweb.be/en/search/house/for-rent?countries=BE&page=1&orderBy=relevance"
r = session.get(URL)
r.html.arender(sleep=1)


# ads = r.html.xpath('//*[@id="searchResults"]/div[4]/div/div[1]/div[1]/div[1]', first=True)

all_tables_from_given_page = []
for item in list(ads):
    try:
        r = session.get(item)

        tables_from_ad = pd.concat(pd.read_html(r.text)).dropna().set_index(0)
        tables_from_ad.loc["day_of_retrieval", 1] = pd.Timestamp.now()
        tables_from_ad.loc["ad_url", 1] = item

        all_tables_from_given_page.append(tables_from_ad)
    except:
        pass
dfs = [
    df.rename(columns={1: f"source_{i}"})
    for i, df in enumerate(all_tables_from_given_page)
]
dfs[0].join(dfs[1:])


dfs_on_disk = []
for i in Path.cwd().glob("*.csv"):
    temp = pd.read_csv(i)
    dfs_on_disk.append(temp)


columns_to_keep = (
    pd.concat(dfs_on_disk, axis=0)
    .loc[:, lambda df: ~df.columns.str.contains("Armored")]
    .isna()
    .sum()
    .div(1458)
    .mul(100)
    .sort_values()
    .head(30)
    .index.to_list()
)


(
    pd.concat(dfs_on_disk, axis=0)
    .loc[:, lambda df: df.columns.isin(columns_to_keep)]
    .ad_url.unique()
    .shape
)























URL = "https://www.immoweb.be/en/classified/house/for-rent/zaventem%20sterrebeek/1933/10792058"
session = HTMLSession(
    browser_args=[
        "--no-sandbox",
        "--user-agent=Mozilla/5.0 (Windows NT 5.1; rv:7.0.1) Gecko/20100101 Firefox/7.0.1",
    ]
)
r = session.get(URL)
r.html.arender(sleep=1)
pd.read_html(r.text)[6]


dfs = [
    add1,
    add2,
]
dfs = [df.set_index(0) for df in dfs]
dfs[0].join(dfs[1:])


add1






































# this one needs selenium


def find_last_page(soup):
    divs = int(soup.find_all("span", class_="button__label")[-1].text)
    return divs


def extract_selenium(type_, page):
    """
    Extracts and returns the BeautifulSoup object from a specified Immoweb search page.

    Args:
        type_ (str): The type of property to search for (e.g., "rent", "sale").
        page (int): The page number of the search results.

    Returns:
        BeautifulSoup: A BeautifulSoup object containing the parsed HTML content of the Immoweb search page.
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.134 Safari/537.36"
    }
    url = f"https://www.immoweb.be/en/search/house/for-{type_}?countries=BE&page={page}&orderBy=relevance"
    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))

    driver.get(url)
    soup = BeautifulSoup(driver.page_source, "lxml")
    return soup





%%script echo skipping

rent_last_page=find_last_page(extract_selenium('rent',1)) + 1


%%script echo skipping

buy_last_page=find_last_page(extract_selenium('buy',1)) + 1


%%script echo skipping

hitlist = []

for i in tqdm.tqdm(range(1, buy_last_page)):
    results = extract(type_ = 'sale',page = i)
    transform(results)
    time.sleep(2)

(pd.DataFrame(hitlist)
 .to_parquet('for_sale.parquet.gzip')
)


%%script echo skipping
hitlist = []

for i in tqdm.tqdm(range(1, 5)):
    results = extract(type_ = 'rent',page = i)
    transform(results)
    time.sleep(2)

(pd.DataFrame(hitlist)
 .to_parquet('for_rent.parquet.gzip')
)


df_sale = pd.read_parquet("for_sale.parquet.gzip")
df_rent = pd.read_parquet("for_rent.parquet.gzip")








%%script echo skipping

locations = []

unique_apartment_locations = (df_rent['ZIP'].astype(str) + ',' + df_rent['city']).unique()

geolocator = Nominatim(user_agent="myApp")

for idx, element in tqdm.tqdm(enumerate(unique_apartment_locations)):
    try:
        location = geolocator.geocode(unique_apartment_locations[idx])
        case = {
            'latitude' : location.latitude,
            'longitude' : location.longitude,
            'address' : location.address
        }

        locations.append(case)

    except AttributeError:
        location = geolocator.geocode(unique_apartment_locations[idx])
        case = {
            'latitude' : np.nan,
            'longitude' : np.nan,
            'address' : np.nan
        }

        locations.append(case)
pd.DataFrame(locations).to_parquet('locations_for_rent.parquet.gzip', compression='gzip') #saving coordinates to disk


locations = pd.read_parquet(
    "locations_for_rent.parquet.gzip"
)  # reading back the saved locations data
locations


locations2 = pd.concat(
    [locations, pd.Series(unique_apartment_locations, name="unique_address")], axis=1
)


(
    df_rent.assign(
        ZIP_city=lambda df: df["ZIP"].astype(str) + "," + df["city"],
        full_address=lambda df: df.ZIP_city.map(
            locations2.set_index("unique_address").address.to_dict()
        ),
        latitude=lambda df: df.ZIP_city.map(
            locations2.set_index("unique_address").latitude.to_dict()
        ),
        longitude=lambda df: df.ZIP_city.map(
            locations2.set_index("unique_address").longitude.to_dict()
        ),
    )
)
































# | fig-cap: "Most Commonly Used Terms in Spam Messages"
# | label: fig-fig1
